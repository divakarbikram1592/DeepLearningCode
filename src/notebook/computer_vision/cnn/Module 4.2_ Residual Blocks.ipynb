{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Residual.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JqclU7Kz5D8",
    "colab_type": "text"
   },
   "source": [
    "## Module 4.2: Residual Blocks/Connections\n",
    "\n",
    "We will see how to create residual blocks/connections layers for use in advanced convolutional neural networks.\n",
    "\n",
    "We will:\n",
    "- Implement basic and convoluted residual blocks. In the first case we will look at connections skipping single or multiple layers.\n",
    "- Create basic models and visually examine the residual architecture.\n",
    "\n",
    "Since we are looking at *layers* rather than networks, we will not solve a problem in this module. However it is a good exercise for you to try on your own to make use of these ideas to improve the CNN performance from module 2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkCvdx1Vz56I",
    "colab_type": "text"
   },
   "source": [
    "We import desired libraries."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uHLMLtqVkCXR",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-02-28T06:49:23.003018Z",
     "start_time": "2024-02-28T06:49:11.849943Z"
    }
   },
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Conv2D,Flatten,Dense,Add,BatchNormalization,Activation\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 12:19:13.892473: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frXfooI3wQM3",
    "colab_type": "text"
   },
   "source": [
    "We will implement a function to create a block of simple residual layers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O_8ljkk3um0Y",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-02-28T06:49:43.126466Z",
     "start_time": "2024-02-28T06:49:43.095273Z"
    }
   },
   "source": [
    "# Since all layers will have the same number of filters to ensure element wise\n",
    "# addition we could do this without a vector of filter numbers. But it will help\n",
    "# to use such vectors once we generalize.\n",
    "def simple_residual_block (layer_in,filters):\n",
    "  # Define first convolution layer\n",
    "  prev_layer = Conv2D(filters[0], (3,3), padding='same', activation='relu')(layer_in)\n",
    "    \n",
    "  for f in range(1,len(filters)):\n",
    "    # Define later convolution layers\n",
    "    conv = Conv2D(filters[f], (3,3), padding='same', activation='relu')(prev_layer)\n",
    "    # Define skip connection (& update prev_layer)\n",
    "    prev_layer = Add()([prev_layer, conv]) \n",
    "  \n",
    "  return prev_layer"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVEaIDpAzyfs",
    "colab_type": "text"
   },
   "source": [
    "Here we design a simple network with such a residual block, and plot the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ihiwkBnskFus",
    "colab_type": "code",
    "outputId": "87ca7151-2091-4549-e7d0-11ddd131697c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1571903950272,
     "user_tz": -120,
     "elapsed": 1399,
     "user": {
      "displayName": "Michael Ashcroft",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAaRQqpOuFHR3D_ZulW6qlXPomIq5vZ-wR4ZuIm=s64",
      "userId": "16725792548700883920"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T06:51:15.683958Z",
     "start_time": "2024-02-28T06:50:22.121103Z"
    }
   },
   "source": [
    "# Define input\n",
    "inputs = Input(shape=(128, 128, 3))\n",
    "# Define residual block\n",
    "res_block=simple_residual_block(inputs,[128,128,128])\n",
    "# Flatten for output\n",
    "flat = Flatten()(res_block)\n",
    "dense1 = Dense(256, activation='relu')(flat)\n",
    "outputs = Dense(10, activation='softmax')(dense1)\n",
    "# Create model\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "# Summarize model\n",
    "model1.summary()\n",
    "# Plot model graph\n",
    "plot_model(model1, show_shapes=True, to_file='residual_module.png')"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  3584        ['input_2[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_3[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 128, 128, 12  0           ['conv2d_3[0][0]',               \n",
      "                                8)                                'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 12  147584      ['add_2[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 128, 128, 12  0           ['add_2[0][0]',                  \n",
      "                                8)                                'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2097152)      0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          536871168   ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           2570        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 537,172,490\n",
      "Trainable params: 537,172,490\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqGSYazWpuII",
    "colab_type": "text"
   },
   "source": [
    "Where we have multiple layers in a basic block - such as a convolution + batch normalization + activation set - we would skip the block. The same is true of convolution + pooling or convolution + dropout layer sets (though care has to be taken to ensure that the resulting outputs match in size, and these are not so commonly used in residual networks).\n",
    "\n",
    "Let's redo our wrapper function to implement a block of residual layers with convolution + batch normalization + activation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xOcZbIaIxAwP",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-02-28T06:51:52.291993Z",
     "start_time": "2024-02-28T06:51:52.288046Z"
    }
   },
   "source": [
    "# Since all layers will have the same number of filters to ensure element wise\n",
    "# addition we could do this without a vector of filter numbers. But it will help\n",
    "# to use such vectors once we generalize.\n",
    "def batchnormed_residual_block (layer_in,filters):\n",
    "  # Define first convolution layer\n",
    "  prev_layer = Conv2D(filters[0], (3,3), padding='same', activation='relu')(layer_in)\n",
    "    \n",
    "  for f in range(1,len(filters)):\n",
    "    # Define later convolution layers\n",
    "    conv = Conv2D(filters[f], (3,3), padding='same')(prev_layer)\n",
    "    batch = BatchNormalization()(conv)\n",
    "    act = Activation(\"relu\")(batch)\n",
    "    # Define skip connection (& update prev_layer)\n",
    "    prev_layer = Add()([prev_layer, act]) \n",
    "  \n",
    "  return prev_layer"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dt7gPhhwbyg",
    "colab_type": "text"
   },
   "source": [
    "And let's design another simple network with two of these new residual blocks, and plot the network architecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OEJCAWKzpuST",
    "colab_type": "code",
    "outputId": "3bd29d99-411e-4cc2-a113-7329087a6184",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1571904108203,
     "user_tz": -120,
     "elapsed": 2709,
     "user": {
      "displayName": "Michael Ashcroft",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAaRQqpOuFHR3D_ZulW6qlXPomIq5vZ-wR4ZuIm=s64",
      "userId": "16725792548700883920"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T06:52:05.928852Z",
     "start_time": "2024-02-28T06:51:54.639637Z"
    }
   },
   "source": [
    "# Define input\n",
    "inputs = Input(shape=(128, 128, 3))\n",
    "# Define first residual block\n",
    "res_block1 = batchnormed_residual_block(inputs,[128,128,128])\n",
    "# Define second residual block\n",
    "res_block2 = batchnormed_residual_block(res_block1,[64,64,64])\n",
    "# Flatten for output\n",
    "flat = Flatten()(res_block2)\n",
    "dense1 = Dense(256, activation='relu')(flat)\n",
    "outputs = Dense(10, activation='softmax')(dense1)\n",
    "# Create model\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "# Summarize model\n",
    "model1.summary()\n",
    "# Plot model graph\n",
    "plot_model(model1, show_shapes=True, to_file='residual_module.png')"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 128, 12  3584        ['input_3[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_6[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 12  512        ['conv2d_7[0][0]']               \n",
      " alization)                     8)                                                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 128, 128, 12  0           ['batch_normalization[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 128, 128, 12  0           ['conv2d_6[0][0]',               \n",
      "                                8)                                'activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 128, 128, 12  147584      ['add_4[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 12  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_1[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 128, 128, 12  0           ['add_4[0][0]',                  \n",
      "                                8)                                'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 64  73792       ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 128, 128, 64  0           ['conv2d_9[0][0]',               \n",
      "                                )                                 'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 128, 64  36928       ['add_6[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 64  256        ['conv2d_11[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 128, 128, 64  0           ['add_6[0][0]',                  \n",
      "                                )                                 'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1048576)      0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          268435712   ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 10)           2570        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 268,886,218\n",
      "Trainable params: 268,885,450\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naYShMTiucKW",
    "colab_type": "text"
   },
   "source": [
    "We may also want to skip sets of convolution (or convolution + other sets) layers. So let's design a wrapper for such a purpose."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zy7Uic6Qyw-1",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-02-28T06:52:20.068660Z",
     "start_time": "2024-02-28T06:52:16.586690Z"
    }
   },
   "source": [
    "# Since all layers will have the same number of filters to ensure element wise\n",
    "# addition we could do this without a vector of filter numbers. But it will help\n",
    "# to use such vectors once we generalize.\n",
    "def convset_residual_block (layer_in,filters,n):\n",
    "  # Make internal function for defining set of convolution layers\n",
    "  def make_conv_set(layer,f_):\n",
    "    for c in range(n):\n",
    "      layer = Conv2D(filters[f_], (3,3), padding='same', activation='relu')(layer)\n",
    "    return layer\n",
    "\n",
    "  # Define first set of convolution layers\n",
    "  prev_layer=make_conv_set(layer_in,0)\n",
    "    \n",
    "  for f in range(1,len(filters)):\n",
    "    # Define later set of convolution layers\n",
    "    conv_set = make_conv_set(prev_layer,f)\n",
    "    # Define skip connection (& update prev_layer)\n",
    "    prev_layer = Add()([prev_layer, conv_set]) \n",
    "  \n",
    "  return prev_layer"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKzG0bgzyxP9",
    "colab_type": "text"
   },
   "source": [
    "And let's design another simple network with two of these new residual blocks, and plot the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-af1cLo8vB2o",
    "colab_type": "code",
    "outputId": "808f688d-98f3-4ebb-86b6-f0dc4387566b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1571907630842,
     "user_tz": -120,
     "elapsed": 2318,
     "user": {
      "displayName": "Michael Ashcroft",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAaRQqpOuFHR3D_ZulW6qlXPomIq5vZ-wR4ZuIm=s64",
      "userId": "16725792548700883920"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T06:52:37.004291Z",
     "start_time": "2024-02-28T06:52:22.838155Z"
    }
   },
   "source": [
    "inputs = Input(shape=(128, 128, 3))\n",
    "# Define first *set* of convolution layers\n",
    "conv1 = convset_residual_block(inputs,[128,128,128],2)\n",
    "# Define second *set* of convolution layers\n",
    "conv2 = convset_residual_block(conv1,[64,64,64],2)\n",
    "# Flatten for output\n",
    "flat = Flatten()(conv2)\n",
    "dense1 = Dense(256, activation='relu')(flat)\n",
    "outputs = Dense(10, activation='softmax')(dense1)\n",
    "# Create model\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "# Summarize model\n",
    "model1.summary()\n",
    "# Plot model graph\n",
    "plot_model(model1, show_shapes=True, to_file='residual_module.png')"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 12  3584        ['input_4[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_12[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_13[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_14[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 128, 128, 12  0           ['conv2d_13[0][0]',              \n",
      "                                8)                                'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 12  147584      ['add_8[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_16[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 128, 128, 12  0           ['add_8[0][0]',                  \n",
      "                                8)                                'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 64  73792       ['add_9[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_18[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_19[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_20[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 128, 128, 64  0           ['conv2d_19[0][0]',              \n",
      "                                )                                 'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 128, 128, 64  36928       ['add_10[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_22[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 128, 128, 64  0           ['add_10[0][0]',                 \n",
      "                                )                                 'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 1048576)      0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256)          268435712   ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 10)           2570        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 269,438,218\n",
      "Trainable params: 269,438,218\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb5h6DK-yBFJ",
    "colab_type": "text"
   },
   "source": [
    "In our last example we create a wrapper function to define a residual block of convolution blocks where the shape of the output has changed. We add a convolution layer to the skip connection designed to suitably shape it for the desired addition. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YHqAcMgv8edd",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2024-02-28T06:53:33.115703Z",
     "start_time": "2024-02-28T06:53:33.065269Z"
    }
   },
   "source": [
    "# Filters will be a 2d numpy array, giving filters for each convolution layer\n",
    "# for each block (rows=block,columns=filter)\n",
    "def dimchanged_convset_residual_block (layer_in,filters):\n",
    "  # Make internal function for defining set of convolution layers\n",
    "  def make_conv_set(layer,f_):\n",
    "    for i in range(filters.shape[1]):\n",
    "      layer = Conv2D(filters[f_,i], (3,3), activation='relu')(layer)\n",
    "    return layer\n",
    "\n",
    "  # Define first set of convolution layers\n",
    "  prev_layer=make_conv_set(layer_in,0)\n",
    "  \n",
    "  # Work out dimensionality of skip convolution filter\n",
    "  # (We know all filters in normal convolution layers are 3x3)\n",
    "  skip_filter_dim=(2*filters.shape[1]+1,2*filters.shape[1]+1)\n",
    "    \n",
    "  for f in range(1,len(filters)):\n",
    "    # Define later set of convolution layers\n",
    "    conv_set = make_conv_set(prev_layer,f)\n",
    "    # Define skip connection (& update prev_layer)\n",
    "    # We need a convolution layer designed to match shapes    \n",
    "    skip_conv = Conv2D(filters[f,-1], skip_filter_dim, activation='relu')(prev_layer)\n",
    "    prev_layer = Add()([conv_set, skip_conv]) \n",
    "  \n",
    "  return prev_layer"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx_VAiAP8et1",
    "colab_type": "text"
   },
   "source": [
    "And we create another simple network with one of these new re-sizing residual blocks, and plot the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BYwXDWh8yBUF",
    "colab_type": "code",
    "outputId": "efc3ecdd-c1cf-4c5a-d73d-37355409f42c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1571913136427,
     "user_tz": -120,
     "elapsed": 2409,
     "user": {
      "displayName": "Michael Ashcroft",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAaRQqpOuFHR3D_ZulW6qlXPomIq5vZ-wR4ZuIm=s64",
      "userId": "16725792548700883920"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T06:54:08.459503Z",
     "start_time": "2024-02-28T06:53:34.938323Z"
    }
   },
   "source": [
    "inputs = Input(shape=(128, 128, 3))\n",
    "# Define residual block of blocks of convolution layers that alter dimensionality.\n",
    "filters=np.array([[64,128,256],[256,256,128]])\n",
    "res_block=dimchanged_convset_residual_block(inputs,filters)\n",
    "# Flatten for output\n",
    "flat = Flatten()(res_block)\n",
    "dense1 = Dense(256, activation='relu')(flat)\n",
    "outputs = Dense(10, activation='softmax')(dense1)\n",
    "# Create model\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "# Summarize model\n",
    "model1.summary()\n",
    "# Plot model graph\n",
    "plot_model(model1, show_shapes=True, to_file='residual_module.png')"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 126, 126, 64  1792        ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 124, 124, 12  73856       ['conv2d_24[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 122, 122, 25  295168      ['conv2d_25[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 120, 120, 25  590080      ['conv2d_26[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 118, 118, 25  590080      ['conv2d_27[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 116, 116, 12  295040      ['conv2d_28[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 116, 116, 12  1605760     ['conv2d_26[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 116, 116, 12  0           ['conv2d_29[0][0]',              \n",
      "                                8)                                'conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 1722368)      0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 256)          440926464   ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 10)           2570        ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 444,380,810\n",
      "Trainable params: 444,380,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
