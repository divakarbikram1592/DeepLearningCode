{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "colab": {
   "name": "CNN on handwritten digits-Keras-TF2.X.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x3En3UFo7xk"
   },
   "source": [
    "# CNN on Handwritten Digits with Keras"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HxtCuPFCo7xn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920884804,
     "user_tz": 300,
     "elapsed": 1682,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "fe9b5108-62d7-4d0f-a9bc-3f7f635a24e2",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:10.449389Z",
     "start_time": "2024-02-23T18:16:10.427881Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# !python --version"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JAXgmm7ko7xp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920943772,
     "user_tz": 300,
     "elapsed": 289,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:10.941130Z",
     "start_time": "2024-02-23T18:16:10.913742Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D\n",
    "import tensorflow_datasets as tfds\n",
    "# %matplotlib inline"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCNjd2jko7xp"
   },
   "source": [
    "## Importing the data:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "te0hJgTKo7xq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920948212,
     "user_tz": 300,
     "elapsed": 639,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "df138468-cd80-41ed-f688-8a067e6d373f",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:15.945313Z",
     "start_time": "2024-02-23T18:16:12.380683Z"
    }
   },
   "source": [
    "# Load MNIST dataset from TensorFlow Datasets\n",
    "\n",
    "image_train, label_train = tfds.as_numpy(tfds.load(\n",
    "    'mnist',\n",
    "    split='train',\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,\n",
    "))\n",
    "\n",
    "image_test, label_test = tfds.as_numpy(tfds.load(\n",
    "    'mnist',\n",
    "    split='test',\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,\n",
    "))"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PUvRbW4Fo7xq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920949583,
     "user_tz": 300,
     "elapsed": 195,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "c5b14900-8e1d-4ef2-f074-7be6436ac4f8",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:20.892501Z",
     "start_time": "2024-02-23T18:16:20.868555Z"
    }
   },
   "source": [
    "image_train.shape"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28, 1)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Iw0_E8A0o7xr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920950357,
     "user_tz": 300,
     "elapsed": 3,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "f79e1fd5-e60c-48c3-b8f8-7ad3d9db4ab0",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:21.617310Z",
     "start_time": "2024-02-23T18:16:21.593042Z"
    }
   },
   "source": [
    "label_train.shape"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000,)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JTD50hV5o7xs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920958325,
     "user_tz": 300,
     "elapsed": 205,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:22.527555Z",
     "start_time": "2024-02-23T18:16:22.518283Z"
    }
   },
   "source": [
    "# Reshape the training data to represent one-channel image input(grayscale)\n",
    "img_rows, img_cols = image_train[0].shape[0], image_train[0].shape[1]\n",
    "X_train = image_train.reshape(image_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = image_test.reshape(image_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QMFlpvdBo7xt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920959664,
     "user_tz": 300,
     "elapsed": 193,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "a61491f0-f4f5-4715-a135-d809c504eae2",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:24.310728Z",
     "start_time": "2024-02-23T18:16:24.276617Z"
    }
   },
   "source": [
    "image_train.shape"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28, 1)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QUmVen-So7xv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920961217,
     "user_tz": 300,
     "elapsed": 196,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "1c2bd57e-868c-4cdf-dbcf-5cf6c900c3a2",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:25.616640Z",
     "start_time": "2024-02-23T18:16:25.559661Z"
    }
   },
   "source": [
    "image_test.shape"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 28, 28, 1)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bykxWj_ko7xw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920963488,
     "user_tz": 300,
     "elapsed": 232,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:28.386352Z",
     "start_time": "2024-02-23T18:16:27.422457Z"
    }
   },
   "source": [
    "#Normalize the input data:\n",
    "image_train_std = image_train.astype('float32')/255.\n",
    "image_test_std = image_test.astype('float32')/255."
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mtxTbXk0o7xw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920965908,
     "user_tz": 300,
     "elapsed": 191,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:29.491490Z",
     "start_time": "2024-02-23T18:16:29.451918Z"
    }
   },
   "source": [
    "#One-hot encode the labels:\n",
    "n_classes = len(set(label_train))\n",
    "y_train = np_utils.to_categorical(label_train, n_classes)\n",
    "y_test = np_utils.to_categorical(label_test, n_classes)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EoY_qwlo7xx"
   },
   "source": [
    "## CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xOnzNUZbo7xx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920970145,
     "user_tz": 300,
     "elapsed": 209,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "8514ab4e-6d3f-41d2-e2d2-46175047321c",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:32.884917Z",
     "start_time": "2024-02-23T18:16:32.747216Z"
    }
   },
   "source": [
    "help(Conv2D)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module tensorflow.python.keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(Conv)\n",
      " |  Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), groups=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers or `None`, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`. You can use `None` when\n",
      " |  a dimension has variable size.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  >>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n",
      " |  >>> # size is 4.\n",
      " |  >>> input_shape = (4, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 26, 26, 2)\n",
      " |  \n",
      " |  >>> # With `dilation_rate` as 2.\n",
      " |  >>> input_shape = (4, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 24, 24, 2)\n",
      " |  \n",
      " |  >>> # With `padding` as \"same\".\n",
      " |  >>> input_shape = (4, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 28, 28, 2)\n",
      " |  \n",
      " |  >>> # With extended batch shape [4, 7]:\n",
      " |  >>> input_shape = (4, 7, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 7, 26, 26, 2)\n",
      " |  \n",
      " |  \n",
      " |  Args:\n",
      " |    filters: Integer, the dimensionality of the output space (i.e. the number of\n",
      " |      output filters in the convolution).\n",
      " |    kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
      " |      and width of the 2D convolution window. Can be a single integer to specify\n",
      " |      the same value for all spatial dimensions.\n",
      " |    strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
      " |      the convolution along the height and width. Can be a single integer to\n",
      " |      specify the same value for all spatial dimensions. Specifying any stride\n",
      " |      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n",
      " |    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n",
      " |      to the left/right or up/down of the input such that output has the same\n",
      " |      height/width dimension as the input.\n",
      " |    data_format: A string, one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs. `channels_last` corresponds\n",
      " |      to inputs with shape `(batch_size, height, width, channels)` while\n",
      " |      `channels_first` corresponds to inputs with shape `(batch_size, channels,\n",
      " |      height, width)`. It defaults to the `image_data_format` value found in\n",
      " |      your Keras config file at `~/.keras/keras.json`. If you never set it, then\n",
      " |      it will be `channels_last`.\n",
      " |    dilation_rate: an integer or tuple/list of 2 integers, specifying the\n",
      " |      dilation rate to use for dilated convolution. Can be a single integer to\n",
      " |      specify the same value for all spatial dimensions. Currently, specifying\n",
      " |      any `dilation_rate` value != 1 is incompatible with specifying any stride\n",
      " |      value != 1.\n",
      " |    groups: A positive integer specifying the number of groups in which the\n",
      " |      input is split along the channel axis. Each group is convolved separately\n",
      " |      with `filters / groups` filters. The output is the concatenation of all\n",
      " |      the `groups` results along the channel axis. Input channels and `filters`\n",
      " |      must both be divisible by `groups`.\n",
      " |    activation: Activation function to use. If you don't specify anything, no\n",
      " |      activation is applied (see `keras.activations`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix (see\n",
      " |      `keras.initializers`). Defaults to 'glorot_uniform'.\n",
      " |    bias_initializer: Initializer for the bias vector (see\n",
      " |      `keras.initializers`). Defaults to 'zeros'.\n",
      " |    kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
      " |      matrix (see `keras.regularizers`). \n",
      " |    bias_regularizer: Regularizer function applied to the bias vector (see\n",
      " |      `keras.regularizers`). \n",
      " |    activity_regularizer: Regularizer function applied to the output of the\n",
      " |      layer (its \"activation\") (see `keras.regularizers`).\n",
      " |    kernel_constraint: Constraint function applied to the kernel matrix (see\n",
      " |      `keras.constraints`).\n",
      " |    bias_constraint: Constraint function applied to the bias vector (see\n",
      " |      `keras.constraints`).\n",
      " |  Input shape:\n",
      " |    4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n",
      " |      `data_format='channels_first'`\n",
      " |    or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n",
      " |      `data_format='channels_last'`.\n",
      " |  Output shape:\n",
      " |    4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n",
      " |    `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n",
      " |      (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n",
      " |      and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Returns:\n",
      " |    A tensor of rank 4+ representing\n",
      " |    `activation(conv2d(inputs, kernel) + bias)`.\n",
      " |  \n",
      " |  Raises:\n",
      " |    ValueError: if `padding` is `\"causal\"`.\n",
      " |    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      Conv\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), groups=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Note here that `call()` method in `tf.keras` is little bit different\n",
      " |      from `keras` API. In `keras` API, you can pass support masking for\n",
      " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
      " |      method to support masking.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs` only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask generated\n",
      " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
      " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
      " |            layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after updating\n",
      " |      a layer weights. It can be overridden to finalize any additional layer state\n",
      " |      after a weight update.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5ZF3_bBQo7xy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920983942,
     "user_tz": 300,
     "elapsed": 6069,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:36.908540Z",
     "start_time": "2024-02-23T18:16:35.940895Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUnO0-R7o7xy"
   },
   "source": [
    "## Compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3NNkx76Qo7xy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920984540,
     "user_tz": 300,
     "elapsed": 2,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:52.201362Z",
     "start_time": "2024-02-23T18:16:52.146274Z"
    }
   },
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x8D5oNNNo7xy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627920987307,
     "user_tz": 300,
     "elapsed": 188,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-23T18:16:59.922702Z",
     "start_time": "2024-02-23T18:16:59.895709Z"
    }
   },
   "source": [
    "#hyperparameters\n",
    "batch_size = 128\n",
    "n_epochs = 5"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_50QP0po7xz"
   },
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sT8JZuc2o7xz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627921194408,
     "user_tz": 300,
     "elapsed": 202849,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "7b11090d-bebb-40f5-d829-24f9e1f1d097",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:48:57.119345Z",
     "start_time": "2024-02-23T18:17:58.185729Z"
    }
   },
   "source": [
    "model.fit(image_train, label_train, batch_size=batch_size, epochs=n_epochs)"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 378s 802ms/step - loss: 0.8146 - accuracy: 0.0998\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 383s 816ms/step - loss: 0.1166 - accuracy: 0.0991\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 361s 770ms/step - loss: 0.0927 - accuracy: 0.0988\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 371s 792ms/step - loss: 0.0787 - accuracy: 0.0992\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 365s 779ms/step - loss: 0.0681 - accuracy: 0.0990\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x12fa8ffd0>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q30xh5a0o7xz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627921271912,
     "user_tz": 300,
     "elapsed": 1420,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "61d3804b-88d2-4613-d00a-385a6a5ac710",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:55:15.871652Z",
     "start_time": "2024-02-23T18:55:11.331321Z"
    }
   },
   "source": [
    "#Show the results on the test set:\n",
    "#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 00:25:14.747879: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: logits and labels must have the same first dimension, got logits shape [32,10] and labels shape [320]\n",
      "\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/vs/jqzkvm7s5yv02zzb44xn5ysc0000gn/T/ipykernel_25403/733289214.py\", line 3, in <module>\n      score = model.evaluate(X_test, y_test, verbose=1)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1497, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1327, in test_function\n      return step_function(self, iterator)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1318, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1311, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1272, in test_step\n      self.compiled_loss(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/compile_utils.py\", line 204, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/losses.py\", line 155, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/losses.py\", line 259, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/losses.py\", line 1752, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/backend.py\", line 4977, in sparse_categorical_crossentropy\n      res = nn.sparse_softmax_cross_entropy_with_logits_v2(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,10] and labels shape [320]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_test_function_6426]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Show the results on the test set:\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest loss:\u001B[39m\u001B[38;5;124m'\u001B[39m, score[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest accuracy:\u001B[39m\u001B[38;5;124m'\u001B[39m, score[\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py:1497\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   1495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1496\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 1497\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1499\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/vs/jqzkvm7s5yv02zzb44xn5ysc0000gn/T/ipykernel_25403/733289214.py\", line 3, in <module>\n      score = model.evaluate(X_test, y_test, verbose=1)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1497, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1327, in test_function\n      return step_function(self, iterator)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1318, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1311, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/training.py\", line 1272, in test_step\n      self.compiled_loss(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/engine/compile_utils.py\", line 204, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/losses.py\", line 155, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/losses.py\", line 259, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/losses.py\", line 1752, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/apple/Documents/Projects-Python/DeepLearningCode/lib/python3.11/site-packages/tensorflow/python/keras/backend.py\", line 4977, in sparse_categorical_crossentropy\n      res = nn.sparse_softmax_cross_entropy_with_logits_v2(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,10] and labels shape [320]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_test_function_6426]"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2W9ZBbjo7xz"
   },
   "source": [
    "## Showing predictions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M5Ah9JoDo7xz",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627921276107,
     "user_tz": 300,
     "elapsed": 1211,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "b11aea95-ab56-4b2e-b41c-ce18f7374d44",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:56:07.071693Z",
     "start_time": "2024-02-23T18:55:49.947973Z"
    }
   },
   "source": [
    "preds = model.predict(X_test)\n",
    "n = 10\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')\n",
    "    plt.title(\"Label: {}\\nPredicted: {}\".format(np.argmax(y_test[i]), np.argmax(preds[i])))\n",
    "    plt.axis('off')\n",
    "plt.show()          "
   ],
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x1500 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPP5pFdUo7x0"
   },
   "source": [
    "## Plotting misclassified images:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3mvk7OMno7x0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627921279542,
     "user_tz": 300,
     "elapsed": 628,
     "user": {
      "displayName": "deep ai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfZWDM3qKZbLd0FrGsKXwHUuK8gNMkFMIT4Ye8=s64",
      "userId": "00364258643751704926"
     }
    },
    "outputId": "b14bea4d-e316-485b-bfa2-140454663c8a",
    "ExecuteTime": {
     "end_time": "2024-02-23T18:56:14.958675Z",
     "start_time": "2024-02-23T18:56:13.593673Z"
    }
   },
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "misc = 0\n",
    "for i in range(len(y_test)):\n",
    "    if(misc==10):\n",
    "        break\n",
    "    label = np.argmax(y_test[i])\n",
    "    pred = np.argmax(preds[i])\n",
    "    if label != pred:\n",
    "        plt.subplot(1, n, misc + 1)\n",
    "        plt.imshow(X_test[i, :, :, 0], cmap='gray')\n",
    "        plt.title(\"Label: {}\\nPredicted: {}\".format(label, pred))\n",
    "        plt.axis('off')\n",
    "        misc+=1\n",
    "plt.show()        "
   ],
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x1500 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  }
 ]
}
